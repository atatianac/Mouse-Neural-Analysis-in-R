# Mouse-Neural-Analysis-in-R
STA 141A Course Project on the study "Distributed coding of choice, action, and engagement across the mouse brain" by Steinmetz et al. (2019).

The study "Distributed coding of choice, action, and engagement across the mouse brain" by Steinmetz et al. (2019) focuses on how neural signals across the brain work to encode vision, choice and action. Using neuropixel probes their goal was to map these neural signals across different brain regions. Experiments were performed on 10 mice over 39 sessions, with hundreds of trials in each session. The task was simple. Mice were placed in front of two screens, one on their left and one on their right. The visual stimuli was presented on these screens with contrast levels of the values {0, 0.25, 0.5, 1}, with 0 being the absence of a stimulus. In front of the mice was also a turnable wheel. Success and failure in the task were defined as: 

- When left contrast > right contrast, success (1) if turning the wheel to the right and failure (-1) otherwise.  
- When right contrast > left contrast, success (1) if turning the wheel to the left and failure (-1) otherwise.  
- When both left and right contrasts are zero, success (1) if holding the wheel still for 1.5 seconds and failure (-1) otherwise. 
- When left and right contrasts are equal but non-zero, left or right will be randomly chosen (50%) as the correct choice.

If the mouse succeeded in the task they were rewarded. The activity of the neurons were recorded as spike trains, which is the timestamp when the neuron was fired. In this report we will examine what other variables were collected, the relationships between them, how we can integrate the data and the best way to build a predictive model. We begin by examining some frequency tables and the structure of the different variables. Then we try to integrate across the 18 sessions and 4 mice to better plot our data. In EDA, we plot linegraphs to examine the spike activity over time split by brain areas and then we aggregate the data over brain areas and split based on success rate. We see interesting patterns emerge in these plots. Then we plot bargraphs for the success rate based on contrast relationship to see if any other patterns emerge. In our predictive modeling section, we begin with a few basic models like logistic regression and k nearest neighbor and build on them using different combinations of predictor variables, LASSO, interaction terms, XGBoost and ensemble model. Finally, we test our optimized model on a test data set to evaluate the accuracy of the final model.
